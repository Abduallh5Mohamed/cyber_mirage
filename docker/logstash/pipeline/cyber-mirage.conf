# =============================================================================
# Logstash Pipeline Configuration for Cyber Mirage
# Ingests logs from honeypots, AI agent, and forensics
# =============================================================================

input {
  # Redis input for message queue events
  redis {
    host => "${REDIS_HOST:redis}"
    port => "${REDIS_PORT:6379}"
    password => "${REDIS_PASSWORD:changeme123}"
    data_type => "list"
    key => "logstash:honeypot_logs"
    codec => json
    type => "honeypot"
  }

  redis {
    host => "${REDIS_HOST:redis}"
    port => "${REDIS_PORT:6379}"
    password => "${REDIS_PASSWORD:changeme123}"
    data_type => "list"
    key => "logstash:attack_events"
    codec => json
    type => "attack"
  }

  redis {
    host => "${REDIS_HOST:redis}"
    port => "${REDIS_PORT:6379}"
    password => "${REDIS_PASSWORD:changeme123}"
    data_type => "list"
    key => "logstash:ai_decisions"
    codec => json
    type => "ai_decision"
  }

  redis {
    host => "${REDIS_HOST:redis}"
    port => "${REDIS_PORT:6379}"
    password => "${REDIS_PASSWORD:changeme123}"
    data_type => "list"
    key => "logstash:forensics"
    codec => json
    type => "forensics"
  }

  # File input for log files
  file {
    path => "/logs/honeypot/*.log"
    start_position => "beginning"
    sincedb_path => "/usr/share/logstash/sincedb/honeypot"
    type => "honeypot_file"
    codec => json
  }

  file {
    path => "/logs/attacks/*.log"
    start_position => "beginning"
    sincedb_path => "/usr/share/logstash/sincedb/attacks"
    type => "attack_file"
  }

  # TCP input for syslog-style logs
  tcp {
    port => 5044
    codec => json
    type => "syslog"
  }

  # Beats input for Filebeat
  beats {
    port => 5045
  }
}

filter {
  # Add timestamp if not present
  if ![timestamp] {
    mutate {
      add_field => { "timestamp" => "%{@timestamp}" }
    }
  }

  # Parse honeypot logs
  if [type] == "honeypot" or [type] == "honeypot_file" {
    mutate {
      add_field => { "[@metadata][index]" => "honeypot" }
    }
    
    # Extract attacker IP if present
    if [attacker_ip] {
      geoip {
        source => "attacker_ip"
        target => "geoip"
        database => "/usr/share/GeoIP/GeoLite2-City.mmdb"
      }
    }
    
    # Parse service type
    if [service] {
      mutate {
        add_field => { "service_category" => "%{service}" }
      }
    }
  }

  # Parse attack events
  if [type] == "attack" or [type] == "attack_file" {
    mutate {
      add_field => { "[@metadata][index]" => "attacks" }
    }
    
    # GeoIP lookup
    if [origin] {
      geoip {
        source => "origin"
        target => "attacker_geo"
        database => "/usr/share/GeoIP/GeoLite2-City.mmdb"
      }
    }
    
    # Calculate attack duration if possible
    if [start_time] and [end_time] {
      ruby {
        code => "
          start_time = Time.parse(event.get('start_time')) rescue nil
          end_time = Time.parse(event.get('end_time')) rescue nil
          if start_time && end_time
            event.set('duration_seconds', (end_time - start_time).to_i)
          end
        "
      }
    }

    # Enrich with threat level
    if [attacker_skill] {
      ruby {
        code => "
          skill = event.get('attacker_skill').to_f
          threat_level = case
            when skill >= 8 then 'critical'
            when skill >= 6 then 'high'
            when skill >= 4 then 'medium'
            else 'low'
          end
          event.set('threat_level', threat_level)
        "
      }
    }
  }

  # Parse AI decisions
  if [type] == "ai_decision" {
    mutate {
      add_field => { "[@metadata][index]" => "ai_decisions" }
    }
    
    # Convert reward to float
    if [reward] {
      mutate {
        convert => { "reward" => "float" }
      }
    }
  }

  # Parse forensics events
  if [type] == "forensics" {
    mutate {
      add_field => { "[@metadata][index]" => "forensics" }
    }
    
    # Add hash verification field
    if [evidence_hash] {
      mutate {
        add_field => { "integrity_verified" => true }
      }
    }
  }

  # Common enrichments
  mutate {
    add_field => { 
      "environment" => "${ENVIRONMENT:production}"
      "hostname" => "${HOSTNAME:cyber-mirage}"
    }
  }

  # Remove unnecessary fields
  mutate {
    remove_field => ["host", "agent"]
  }
}

output {
  # Output to Elasticsearch
  elasticsearch {
    hosts => ["${ELASTICSEARCH_HOST:elasticsearch}:${ELASTICSEARCH_PORT:9200}"]
    user => "${ELASTICSEARCH_USER:elastic}"
    password => "${ELASTICSEARCH_PASSWORD:changeme}"
    index => "cyber-mirage-%{[@metadata][index]}-%{+YYYY.MM.dd}"
    ilm_enabled => true
    ilm_rollover_alias => "cyber-mirage-%{[@metadata][index]}"
    ilm_pattern => "000001"
    ilm_policy => "cyber-mirage-policy"
  }

  # Debug output (disable in production)
  # stdout { codec => rubydebug }
}
