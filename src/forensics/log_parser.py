"""
Log Parser - Ù…Ø­Ù„Ù„ Ø§Ù„Ø³Ø¬Ù„Ø§Øª
Cyber Mirage Forensics Module

ÙŠÙ‚ÙˆÙ… Ø¨ØªØ­Ù„ÙŠÙ„:
- Docker container logs
- System logs
- Application logs
- Security logs
"""

import re
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any, Generator
from dataclasses import dataclass, asdict
from enum import Enum
from collections import Counter, defaultdict

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class LogLevel(Enum):
    """Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø³Ø¬Ù„Ø§Øª"""
    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"


@dataclass
class ParsedLogEntry:
    """Ø³Ø¬Ù„ Ù…Ø­Ù„Ù‘Ù„"""
    timestamp: str
    level: str
    source: str
    message: str
    raw_line: str
    metadata: Optional[Dict] = None
    
    def to_dict(self) -> Dict:
        return asdict(self)


@dataclass
class AttackIndicator:
    """Ù…Ø¤Ø´Ø± Ù‡Ø¬ÙˆÙ…"""
    indicator_type: str
    value: str
    confidence: float
    context: str
    timestamp: str


class LogParser:
    """
    Ù…Ø­Ù„Ù„ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ù†Ù…Ø§Ø·
    """
    
    # Ø£Ù†Ù…Ø§Ø· Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¬Ù„Ø§Øª
    LOG_PATTERNS = {
        # Python logging format
        "python": r'^(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d+)\s+(\w+)\s+(.+)$',
        
        # Syslog format
        "syslog": r'^(\w{3}\s+\d{1,2} \d{2}:\d{2}:\d{2})\s+(\S+)\s+(\S+):\s+(.+)$',
        
        # Apache/Nginx access log
        "access": r'^(\S+)\s+-\s+-\s+\[([^\]]+)\]\s+"([^"]+)"\s+(\d+)\s+(\d+)',
        
        # Docker timestamp format
        "docker": r'^(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d+Z?)\s+(.+)$',
        
        # Generic timestamp
        "generic": r'^(\d{4}-\d{2}-\d{2}[T ]\d{2}:\d{2}:\d{2}[^\s]*)\s+(.+)$'
    }
    
    # Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ù‡Ø¬Ù…Ø§Øª
    ATTACK_PATTERNS = {
        "brute_force": [
            r'failed.*login|invalid.*password|authentication.*fail',
            r'too many.*attempts|blocked.*ip|banned',
        ],
        "sql_injection": [
            r"union.*select|'.*or.*'|drop.*table|insert.*into",
            r"exec\(|eval\(|system\(",
        ],
        "xss": [
            r'<script>|javascript:|onerror=|onload=',
            r'document\.cookie|alert\(',
        ],
        "path_traversal": [
            r'\.\./|\.\.\\|%2e%2e|%252e',
            r'/etc/passwd|/etc/shadow|win\.ini',
        ],
        "command_injection": [
            r';\s*cat\s|;\s*ls\s|;\s*rm\s|;\s*wget\s',
            r'\|.*cat|\|.*ls|\|.*rm',
            r'`.*`|\$\(.*\)',
        ],
        "port_scan": [
            r'connection.*refused|port.*scan|nmap',
            r'syn.*scan|fin.*scan',
        ]
    }
    
    # Ø£Ù†Ù…Ø§Ø· Ø§Ø³ØªØ®Ø±Ø§Ø¬ IPs
    IP_PATTERN = re.compile(r'\b(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})\b')
    
    # Ø£Ù†Ù…Ø§Ø· Ø§Ø³ØªØ®Ø±Ø§Ø¬ URLs
    URL_PATTERN = re.compile(r'https?://[^\s<>"{}|\\^`\[\]]+')
    
    def __init__(self):
        """Initialize log parser"""
        self.parsed_entries: List[ParsedLogEntry] = []
        self.attack_indicators: List[AttackIndicator] = []
        self.statistics = defaultdict(int)
    
    def parse_file(self, file_path: str, log_format: str = "auto") -> List[ParsedLogEntry]:
        """
        ØªØ­Ù„ÙŠÙ„ Ù…Ù„Ù Ø³Ø¬Ù„
        
        Args:
            file_path: Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù
            log_format: Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¬Ù„ (auto Ù„Ù„ÙƒØ´Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ)
        
        Returns:
            Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø­Ù„Ù„Ø©
        """
        entries = []
        
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            for line_num, line in enumerate(f, 1):
                entry = self.parse_line(line.strip(), log_format)
                if entry:
                    entry.metadata = entry.metadata or {}
                    entry.metadata["line_number"] = line_num
                    entry.metadata["file"] = file_path
                    entries.append(entry)
        
        self.parsed_entries.extend(entries)
        logger.info(f"Parsed {len(entries)} entries from {file_path}")
        
        return entries
    
    def parse_line(self, line: str, log_format: str = "auto") -> Optional[ParsedLogEntry]:
        """
        ØªØ­Ù„ÙŠÙ„ Ø³Ø·Ø± Ø³Ø¬Ù„ ÙˆØ§Ø­Ø¯
        
        Args:
            line: Ø³Ø·Ø± Ø§Ù„Ø³Ø¬Ù„
            log_format: Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¬Ù„
        
        Returns:
            Ø³Ø¬Ù„ Ù…Ø­Ù„Ù„ Ø£Ùˆ None
        """
        if not line.strip():
            return None
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù…Ø·
        if log_format == "auto":
            for fmt, pattern in self.LOG_PATTERNS.items():
                match = re.match(pattern, line, re.IGNORECASE)
                if match:
                    return self._create_entry(match, fmt, line)
        else:
            pattern = self.LOG_PATTERNS.get(log_format)
            if pattern:
                match = re.match(pattern, line, re.IGNORECASE)
                if match:
                    return self._create_entry(match, log_format, line)
        
        # Ø¥Ø°Ø§ Ù„Ù… ÙŠØªØ·Ø§Ø¨Ù‚ Ù…Ø¹ Ø£ÙŠ Ù†Ù…Ø·
        return ParsedLogEntry(
            timestamp=datetime.now().isoformat(),
            level="UNKNOWN",
            source="unknown",
            message=line,
            raw_line=line
        )
    
    def _create_entry(self, match: re.Match, log_format: str, raw_line: str) -> ParsedLogEntry:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¬Ù„ Ù…Ø­Ù„Ù„ Ù…Ù† Ø§Ù„ØªØ·Ø§Ø¨Ù‚"""
        groups = match.groups()
        
        if log_format == "python":
            return ParsedLogEntry(
                timestamp=groups[0],
                level=groups[1],
                source="python",
                message=groups[2],
                raw_line=raw_line
            )
        elif log_format == "docker":
            return ParsedLogEntry(
                timestamp=groups[0],
                level="INFO",
                source="docker",
                message=groups[1],
                raw_line=raw_line
            )
        elif log_format == "access":
            return ParsedLogEntry(
                timestamp=groups[1],
                level="INFO",
                source=groups[0],  # IP
                message=f"{groups[2]} - Status: {groups[3]}",
                raw_line=raw_line,
                metadata={
                    "ip": groups[0],
                    "request": groups[2],
                    "status_code": groups[3],
                    "bytes": groups[4]
                }
            )
        else:
            return ParsedLogEntry(
                timestamp=groups[0] if groups else datetime.now().isoformat(),
                level="INFO",
                source=log_format,
                message=groups[-1] if groups else raw_line,
                raw_line=raw_line
            )
    
    def detect_attacks(self, entries: List[ParsedLogEntry] = None) -> List[AttackIndicator]:
        """
        Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù‡Ø¬Ù…Ø§Øª
        
        Args:
            entries: Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„ (Ø£Ùˆ ÙƒÙ„ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©)
        
        Returns:
            Ù‚Ø§Ø¦Ù…Ø© Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù‡Ø¬Ù…Ø§Øª
        """
        if entries is None:
            entries = self.parsed_entries
        
        indicators = []
        
        for entry in entries:
            message = entry.message.lower()
            
            for attack_type, patterns in self.ATTACK_PATTERNS.items():
                for pattern in patterns:
                    if re.search(pattern, message, re.IGNORECASE):
                        indicator = AttackIndicator(
                            indicator_type=attack_type,
                            value=entry.message[:100],
                            confidence=0.8,
                            context=entry.raw_line[:200],
                            timestamp=entry.timestamp
                        )
                        indicators.append(indicator)
                        self.statistics[f"attack_{attack_type}"] += 1
                        break
        
        self.attack_indicators.extend(indicators)
        logger.info(f"Detected {len(indicators)} attack indicators")
        
        return indicators
    
    def extract_ips(self, entries: List[ParsedLogEntry] = None) -> Dict[str, int]:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØ¥Ø­ØµØ§Ø¡ Ø¹Ù†Ø§ÙˆÙŠÙ† IP
        
        Args:
            entries: Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„
        
        Returns:
            Ù‚Ø§Ù…ÙˆØ³ {IP: Ø¹Ø¯Ø¯ Ø§Ù„Ø¸Ù‡ÙˆØ±}
        """
        if entries is None:
            entries = self.parsed_entries
        
        ip_counter = Counter()
        
        for entry in entries:
            ips = self.IP_PATTERN.findall(entry.raw_line)
            for ip in ips:
                # ØªØ¬Ø§Ù‡Ù„ IPs Ø§Ù„Ù…Ø­Ù„ÙŠØ©
                if not ip.startswith(('127.', '0.', '255.')):
                    ip_counter[ip] += 1
        
        return dict(ip_counter.most_common())
    
    def extract_urls(self, entries: List[ParsedLogEntry] = None) -> List[str]:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ URLs Ù…Ù† Ø§Ù„Ø³Ø¬Ù„Ø§Øª
        
        Args:
            entries: Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„
        
        Returns:
            Ù‚Ø§Ø¦Ù…Ø© URLs
        """
        if entries is None:
            entries = self.parsed_entries
        
        urls = set()
        
        for entry in entries:
            found_urls = self.URL_PATTERN.findall(entry.raw_line)
            urls.update(found_urls)
        
        return list(urls)
    
    def filter_by_level(self, level: LogLevel) -> List[ParsedLogEntry]:
        """
        ÙÙ„ØªØ±Ø© Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ø³ØªÙˆÙ‰
        
        Args:
            level: Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø³Ø¬Ù„
        
        Returns:
            Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
        """
        return [e for e in self.parsed_entries if e.level == level.value]
    
    def filter_by_ip(self, ip: str) -> List[ParsedLogEntry]:
        """
        ÙÙ„ØªØ±Ø© Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø­Ø³Ø¨ IP
        
        Args:
            ip: Ø¹Ù†ÙˆØ§Ù† IP
        
        Returns:
            Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
        """
        return [e for e in self.parsed_entries if ip in e.raw_line]
    
    def filter_by_keyword(self, keyword: str) -> List[ParsedLogEntry]:
        """
        ÙÙ„ØªØ±Ø© Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø­Ø³Ø¨ ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ©
        
        Args:
            keyword: Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
        
        Returns:
            Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
        """
        keyword_lower = keyword.lower()
        return [e for e in self.parsed_entries if keyword_lower in e.raw_line.lower()]
    
    def get_error_summary(self) -> Dict[str, Any]:
        """
        Ù…Ù„Ø®Øµ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª
        
        Returns:
            Ù…Ù„Ø®Øµ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
        """
        errors = self.filter_by_level(LogLevel.ERROR)
        criticals = self.filter_by_level(LogLevel.CRITICAL)
        warnings = self.filter_by_level(LogLevel.WARNING)
        
        # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù…ØªØ´Ø§Ø¨Ù‡Ø©
        error_patterns = Counter()
        for entry in errors + criticals:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙˆÙ„ 50 Ø­Ø±Ù ÙƒÙ…ÙØªØ§Ø­
            key = entry.message[:50]
            error_patterns[key] += 1
        
        return {
            "total_errors": len(errors),
            "total_criticals": len(criticals),
            "total_warnings": len(warnings),
            "top_errors": dict(error_patterns.most_common(10)),
            "first_error": errors[0].to_dict() if errors else None,
            "last_error": errors[-1].to_dict() if errors else None
        }
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ø³Ø¬Ù„Ø§Øª
        
        Returns:
            Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        """
        level_counts = Counter(e.level for e in self.parsed_entries)
        source_counts = Counter(e.source for e in self.parsed_entries)
        
        return {
            "total_entries": len(self.parsed_entries),
            "by_level": dict(level_counts),
            "by_source": dict(source_counts.most_common(10)),
            "attack_indicators": len(self.attack_indicators),
            "unique_ips": len(self.extract_ips()),
            "unique_urls": len(self.extract_urls()),
            "attack_statistics": dict(self.statistics)
        }
    
    def export_json(self, file_path: str) -> str:
        """
        ØªØµØ¯ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù„Ù…Ù„Ù JSON
        
        Args:
            file_path: Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù
        
        Returns:
            Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù
        """
        export_data = {
            "metadata": {
                "exported_at": datetime.now().isoformat(),
                "tool": "Cyber Mirage Log Parser"
            },
            "statistics": self.get_statistics(),
            "attack_indicators": [
                {
                    "type": i.indicator_type,
                    "value": i.value,
                    "confidence": i.confidence,
                    "timestamp": i.timestamp
                }
                for i in self.attack_indicators
            ],
            "ip_analysis": self.extract_ips(),
            "entries": [e.to_dict() for e in self.parsed_entries[:1000]]  # Ø£ÙˆÙ„ 1000
        }
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"Exported analysis to {file_path}")
        return file_path
    
    def generate_report(self) -> str:
        """
        ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¬Ù„Ø§Øª
        
        Returns:
            Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†ØµÙŠ
        """
        stats = self.get_statistics()
        error_summary = self.get_error_summary()
        ips = self.extract_ips()
        
        report = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              CYBER MIRAGE - LOG ANALYSIS REPORT                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S'):<50} â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£

ğŸ“Š GENERAL STATISTICS:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Total Log Entries: {stats['total_entries']}
  Attack Indicators: {stats['attack_indicators']}
  Unique IPs: {stats['unique_ips']}

ğŸ“ˆ BY LOG LEVEL:
"""
        for level, count in stats['by_level'].items():
            icon = {"ERROR": "ğŸ”´", "CRITICAL": "â›”", "WARNING": "ğŸŸ¡", "INFO": "ğŸŸ¢"}.get(level, "âšª")
            report += f"  {icon} {level}: {count}\n"
        
        report += "\nâš ï¸ ERROR SUMMARY:\n"
        report += f"  Total Errors: {error_summary['total_errors']}\n"
        report += f"  Total Criticals: {error_summary['total_criticals']}\n"
        
        report += "\nğŸ¯ ATTACK INDICATORS:\n"
        for attack_type, count in stats['attack_statistics'].items():
            report += f"  - {attack_type.replace('attack_', '').upper()}: {count}\n"
        
        report += "\nğŸŒ TOP IPs:\n"
        for ip, count in list(ips.items())[:10]:
            report += f"  - {ip}: {count} occurrences\n"
        
        report += """
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    End of Log Analysis Report
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
        return report


class HoneypotLogParser(LogParser):
    """
    Ù…Ø­Ù„Ù„ Ù…Ø®ØµØµ Ù„Ø³Ø¬Ù„Ø§Øª Honeypots
    """
    
    # Ø£Ù†Ù…Ø§Ø· Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù€ Honeypots
    HONEYPOT_PATTERNS = {
        "connection": r'Connection on port (\d+) from \(\'([^\']+)\', (\d+)\)',
        "attack_logged": r'Logged (\w+) attack from ([\d.]+) to PostgreSQL',
        "threat_intel": r'Logged threat intel to Redis for ([\d.]+)',
        "login_attempt": r'Login attempt.*user[name]*[=:]\s*["\']?(\w+)',
        "command": r'Command executed[=:]\s*(.+)',
    }
    
    def parse_honeypot_log(self, log_content: str) -> Dict[str, Any]:
        """
        ØªØ­Ù„ÙŠÙ„ Ø³Ø¬Ù„ Honeypot
        
        Args:
            log_content: Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø³Ø¬Ù„
        
        Returns:
            Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„
        """
        results = {
            "connections": [],
            "attacks": [],
            "threat_intel": [],
            "login_attempts": [],
            "commands": []
        }
        
        for line in log_content.split('\n'):
            # Ø§ØªØµØ§Ù„Ø§Øª
            match = re.search(self.HONEYPOT_PATTERNS["connection"], line)
            if match:
                results["connections"].append({
                    "port": match.group(1),
                    "ip": match.group(2),
                    "source_port": match.group(3),
                    "raw": line
                })
            
            # Ù‡Ø¬Ù…Ø§Øª Ù…Ø³Ø¬Ù„Ø©
            match = re.search(self.HONEYPOT_PATTERNS["attack_logged"], line)
            if match:
                results["attacks"].append({
                    "service": match.group(1),
                    "ip": match.group(2),
                    "raw": line
                })
            
            # Threat Intel
            match = re.search(self.HONEYPOT_PATTERNS["threat_intel"], line)
            if match:
                results["threat_intel"].append({
                    "ip": match.group(1),
                    "raw": line
                })
        
        return results


if __name__ == "__main__":
    # Ø§Ø®ØªØ¨Ø§Ø±
    parser = LogParser()
    print("Log Parser initialized")
    print(f"Available patterns: {list(parser.LOG_PATTERNS.keys())}")
